# ACT 131125

<mark style="background-color: red;"> Akaal </mark>

 <mark style="background-color:purple; color:black; border-radius: 7px; padding: 2px 4px;">   Differences between linked lists and arrays</mark>

# <mark>take notes on coursework 2</mark>

<img width="460" height="306" alt="image" src="https://github.com/user-attachments/assets/808f01f7-5f46-4574-8ccb-f66bae1a4188" />
<img width="1150" height="574" alt="image" src="https://github.com/user-attachments/assets/acdac9aa-fa59-4d78-a0dc-929cef368c36" />
<img width="166" height="350" alt="image" src="https://github.com/user-attachments/assets/4a89d8f4-2b47-4e9e-a5cf-549307dc2976" />

- "Machine learning: Algorithms that can learn from data to produce an inference which was not coded."

<img width="868" height="478" alt="image" src="https://github.com/user-attachments/assets/a9720ffa-3859-4011-a53b-f43bf8c4837d" />

- "Neural Network: A ML approach which is loosely modelled on the human brain by using layers of connected 'nodes'."
- "Deep Learning: Learning based on the use of a deep (many layered) neural network."

<img width="1158" height="646" alt="image" src="https://github.com/user-attachments/assets/d90de6f2-e33b-4e9d-825a-fe14edf0ab54" />

<img width="1035" height="643" alt="image" src="https://github.com/user-attachments/assets/90625ece-01e3-4b7e-8b66-c945e222669c" />

<img width="1142" height="621" alt="image" src="https://github.com/user-attachments/assets/4d318e6e-f204-431d-a3e4-2026c0adcd3c" />

<img width="1140" height="621" alt="image" src="https://github.com/user-attachments/assets/fc8f42c8-5fd7-4cba-83ed-729df20d0ad4" />

<img width="1157" height="653" alt="image" src="https://github.com/user-attachments/assets/62be11cd-72ef-46ff-9c6c-640c48aab88f" />

## Key Maths
- Vectors and matrices
- - These represent the inputs, outputs, hidden layers and how to transform the parameters which control the features that the algorithm optimises 
- - e.g. weights and biases. Some traditional ML techniques use distances between vectors or their projection onto lower dimensional planes.
- Calculus
- - This is required to optimise the network.
  - We find derivatives in order to know if we are sitting in a minima or not and to drive the direction of optimisation of the weights, this is called ‘gradient descent’.
  - We use the chain rule to update these derivatives through the network, this is called ‘backpropagation’.
- Probability
- - probability distributions are used often in ‘cost’ functions
  - e.g. understanding how far away from an optimal solution we are; in ‘activation functions’, that is functions which allow non-linearities; and all probabilistic ML algorithms. 

<img width="1168" height="659" alt="image" src="https://github.com/user-attachments/assets/54083dd0-fd5d-4951-b87b-e82ae8ed3418" />

<img width="1128" height="651" alt="image" src="https://github.com/user-attachments/assets/40c3401d-15f4-4203-a576-981869670e45" />

<img width="1159" height="671" alt="image" src="https://github.com/user-attachments/assets/e027ed0c-99e6-444f-bfab-f14c43022a2c" />

<img width="1105" height="678" alt="image" src="https://github.com/user-attachments/assets/07d16378-32bd-45cc-9305-e9a6c42c0d15" />

<img width="1047" height="582" alt="image" src="https://github.com/user-attachments/assets/0e1f77ec-c62b-4996-9226-bd9b61e6f5b7" />

<img width="1134" height="645" alt="image" src="https://github.com/user-attachments/assets/1ca260ce-3041-4339-af19-0ae9250bfa07" />

<img width="1061" height="548" alt="image" src="https://github.com/user-attachments/assets/d3031a99-ee45-46d4-ab02-9cc3f32bd910" />

<img width="1116" height="607" alt="image" src="https://github.com/user-attachments/assets/623df2ad-9657-438c-9e48-99db18a732af" />

<img width="1251" height="694" alt="image" src="https://github.com/user-attachments/assets/778727f3-51fa-4f9b-810f-19e00ec0c46f" />

<img width="1175" height="717" alt="image" src="https://github.com/user-attachments/assets/42c307eb-24b7-4449-af0e-a9ad22856490" />

